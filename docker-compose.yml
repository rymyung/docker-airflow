version: '3'

services:
  postgres:
    image: postgres:13
    env_file:
      - config/common.env
    volumes:
      - ./pgdata:/var/lib/postgresql/data
    ports:
      - 5432:5432
    user: postgres
    restart: always

  redis:
    image: redis:latest
    env_file:
      - config/common.env
    ports:
      - 6379:6379
    restart: always

  init:
    image: sist/airflow:2.1.0
    env_file:
      - config/common.env
    depends_on:
      - postgres
      - redis
    environment:
      - _AIRFLOW_DB_INIT=true
      - _AIRFLOW_USER_CREATE=true
    volumes:
      - ./airflow:/airflow
    command: version


  webserver:
    image: sist/airflow:2.1.0
    env_file:
      - config/common.env
    depends_on:
      - init
    volumes:
      - ./airflow:/airflow
    ports:
      - 8080:8080
    command: webserver
    restart: always


  scheduler:
    image: sist/airflow:2.1.0
    env_file:
      - config/common.env
    depends_on:
      - init
    volumes:
      - ./airflow:/airflow
    command: scheduler
    restart: always


  worker:
    image: sist/airflow:2.1.0
    env_file:
      - config/common.env
    environment:
      - QUEUE_NAME=queue_1
    depends_on:
      - webserver
    volumes:
      - ./airflow:/airflow
    ports:
      - 8081:8080
    command: celery worker
    restart: always


  flower:
    image: sist/airflow:2.1.0
    env_file:
      - config/common.env
    depends_on:
      - webserver
    volumes:
      - ./airflow:/airflow
    ports:
      - 5555:5555
    command: celery flower
    restart: always

  spark-master:
      image: bde2020/spark-master:3.1.1-hadoop3.2
      container_name: spark-master
      ports:
        - 28080:8080
        - 27077:7077
      environment:
        - INIT_DAEMON_STEP=setup_spark
      restart: always

  spark-worker-1:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - 28081:8081
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    restart: always

  spark-worker-2:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - 28082:8081
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    restart: always
  